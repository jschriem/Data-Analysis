## Lab 10: Web scraping with Selenium 

In the last 20 minutes of the lab you will be given time to complete the TA evaluation. As usual, once you have demoed you are free to leave, but it's appreciated if students take the time (in the lab or not) to complete the TA evaluation. You do the lab writeup at https://evals.csc.uvic.ca. 
#### Lab Outline 

The goal of this lab is to use Selenium to build a simple web scraping tool. Selenium has become widely adopted for testing, however, at it's core it's a browser automation tool that has a variety of uses. There are a number of benefits to using Selenium for this type of task, one one of which is it can be very difficult to navigate links generated by Javascript simply using requests, whereas this behaviour is intuitive when working with selenium. 

More specifically, for this lab you will need to:

- Choose some website to target
- Implement a selenium script that navigates to that website, and scrapes some data from it. 
- Saves the data to a file on your machine. 

These instructions are intentionally vague, try and be creative.

### Setup

Just like previous labs, export your path and run setup.sh:

```
export PATH=$PATH:/home/{USER}/.local/bin
chmod u+x setup.sh  
source ./setup.sh` 
```

If you are working on your own laptop, the version of the chromedriver that you need will be different. Ask your instructor for help finding it if you need. 

### Implementation Advice

Consider this snippet from the accompanied `craigslist_ex.py` file. It navigates from the craigslist home page, to the first page of apartment rentals, and saves both the name and the price of each rental on that page to a text file. You should understand how this code works at least at a high level, and potentially use the accompanied file as a jumping-off point. 

```python
        self.driver.get('https://vancouver.craigslist.ca/')

        options = self.driver.find_element_by_id('hhh0')
        # hack to get all the <li> elements
        options = options.find_elements_by_css_selector('*')
        target = options[0]
        target.click()

        titles = self.driver.find_elements_by_class_name('result-title')
        prices = self.driver.find_elements_by_class_name('result-price')

        results = [(title.text, price.text) for title, price in zip(titles, prices)]

        with open('craigslist-page1-housing-stats.txt', 'w') as f:
            f.write(str(results))
```

#### Evaluation 

If you choose craigslist.com, expectations will be slightly higher given the starter code. 

- Your program navigates through the website by  clicking on links. To get full marks for this section, your program must navigate across at least two distinct pages.
- You save (whatever data*) you were scraping into a text file locally 
- Your program runs for a variable length. Ie, if the example craigslist implementation were to continue clicking onto the next page, scraping the results there, and then continuing on. 
